{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MedXpert/src/ui/pages/compare.py\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from src.pipeline.blip_captioning import generate_blip_captions\n",
    "from src.pipeline.llm_report_generation import generate_report\n",
    "from src.llm_providers import llm_fn\n",
    "\n",
    "st.header(\"üîç Compare Two X-ray Images\")\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    img1 = st.file_uploader(\"Upload first image\", type=[\"png\", \"jpg\", \"jpeg\"], key=\"img1\")\n",
    "\n",
    "with col2:\n",
    "    img2 = st.file_uploader(\"Upload second image\", type=[\"png\", \"jpg\", \"jpeg\"], key=\"img2\")\n",
    "\n",
    "def save_temp_image(uploaded_file):\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    temp_img_path = os.path.join(temp_dir, uploaded_file.name)\n",
    "    with open(temp_img_path, \"wb\") as f:\n",
    "        f.write(uploaded_file.getbuffer())\n",
    "    return temp_img_path\n",
    "\n",
    "if st.button(\"Compare & Analyze\"):\n",
    "    if not img1 or not img2:\n",
    "        st.warning(\"Please upload both images.\")\n",
    "    else:\n",
    "        img1_path = save_temp_image(img1)\n",
    "        img2_path = save_temp_image(img2)\n",
    "\n",
    "        captions = generate_blip_captions([img1_path, img2_path])\n",
    "\n",
    "        st.subheader(\"üñºÔ∏è BLIP Captions\")\n",
    "        st.markdown(f\"**Image 1:** {captions[0]}\")\n",
    "        st.markdown(f\"**Image 2:** {captions[1]}\")\n",
    "\n",
    "        st.subheader(\"üìã Comparative Diagnosis (via LLM)\")\n",
    "        prompt = f\"\"\"\n",
    "Compare the following radiology findings from two X-rays:\n",
    "\n",
    "Image 1: {captions[0]}\n",
    "Image 2: {captions[1]}\n",
    "\n",
    "What are the differences or changes observed?\n",
    "\"\"\"\n",
    "        comparison_report = llm_fn(prompt)\n",
    "        st.text_area(\"Comparative Analysis\", comparison_report, height=300)\n",
    "\n",
    "# MedXpert/src/ui/pages/diagnosis.py\n",
    "\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "from src.pipeline.blip_captioning import generate_blip_captions\n",
    "from src.pipeline.llm_report_generation import generate_report\n",
    "from src.llm_providers import llm_fn  # Real LLM interface\n",
    "\n",
    "st.header(\"ü©ª Direct Diagnosis from X-ray\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload a chest X-ray image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "\n",
    "def save_temp_image(file):\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    img_path = os.path.join(temp_dir, file.name)\n",
    "    with open(img_path, \"wb\") as f:\n",
    "        f.write(file.getbuffer())\n",
    "    return img_path\n",
    "\n",
    "if st.button(\"Generate Diagnosis\"):\n",
    "    if not uploaded_file:\n",
    "        st.warning(\"Please upload an image.\")\n",
    "    else:\n",
    "        image_path = save_temp_image(uploaded_file)\n",
    "\n",
    "        st.subheader(\"üß† Image Caption (via BLIP)\")\n",
    "        caption = generate_blip_captions([image_path])[0]\n",
    "        st.info(f\"üìù Caption: {caption}\")\n",
    "\n",
    "        st.subheader(\"üìã Diagnostic Report (via LLM)\")\n",
    "        report = generate_report([caption], [], llm_fn)\n",
    "        st.text_area(\"Generated Diagnosis\", report, height=300)\n",
    "\n",
    "\n",
    "\n",
    "# MedXpert/src/ui/pages/search.py\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "from src.pipeline.clip_retrieval import retrieve_top_k\n",
    "from src.pipeline.blip_captioning import generate_blip_captions\n",
    "from src.pipeline.llm_report_generation import generate_report\n",
    "from src.llm_providers import llm_fn  # your actual LLM API function\n",
    "\n",
    "st.header(\"üîé Visual + Text Search\")\n",
    "\n",
    "mode = st.radio(\"Choose retrieval mode:\", [\"Text ‚Üí Image/Text\", \"Image ‚Üí Text\"])\n",
    "top_k = st.slider(\"How many results to retrieve?\", 1, 10, 3)\n",
    "\n",
    "# Load test dataset\n",
    "@st.cache_data\n",
    "def load_dataset():\n",
    "    with open(\"data/processed/texts/test.json\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "dataset = load_dataset()\n",
    "\n",
    "def save_temp_image(uploaded_file):\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    path = os.path.join(temp_dir, uploaded_file.name)\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(uploaded_file.getbuffer())\n",
    "    return path\n",
    "\n",
    "def display_results(indices):\n",
    "    samples = [dataset[i] for i in indices]\n",
    "    image_paths = [s[\"image_id\"] for s in samples]\n",
    "    texts = [s[\"text\"] for s in samples]\n",
    "\n",
    "    st.subheader(\"üì∏ Retrieved X-ray Images + Captions\")\n",
    "    captions = generate_blip_captions(image_paths)\n",
    "\n",
    "    cols = st.columns(len(image_paths))\n",
    "    for i, col in enumerate(cols):\n",
    "        col.image(image_paths[i], caption=captions[i], use_column_width=True)\n",
    "\n",
    "    st.subheader(\"üìù AI-Generated Diagnostic Report\")\n",
    "    report = generate_report(captions, texts, llm_fn)\n",
    "    st.text_area(\"Report Output\", report, height=250)\n",
    "\n",
    "# User input section\n",
    "if mode == \"Text ‚Üí Image/Text\":\n",
    "    query = st.text_input(\"Enter medical query:\", \"What abnormality is present?\")\n",
    "    if st.button(\"Search & Generate Report\"):\n",
    "        if not query:\n",
    "            st.warning(\"Please enter a valid query.\")\n",
    "        else:\n",
    "            indices, _ = retrieve_top_k(query, mode=\"text\", k=top_k)\n",
    "            display_results(indices)\n",
    "\n",
    "elif mode == \"Image ‚Üí Text\":\n",
    "    uploaded_file = st.file_uploader(\"Upload chest X-ray:\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "    if st.button(\"Search & Generate Report\"):\n",
    "        if not uploaded_file:\n",
    "            st.warning(\"Please upload a file.\")\n",
    "        else:\n",
    "            image_path = save_temp_image(uploaded_file)\n",
    "            indices, _ = retrieve_top_k(image_path, mode=\"image\", k=top_k)\n",
    "            display_results(indices)\n",
    "\n",
    "\n",
    "# /home/sysadm/Music/MedXpert/src/ui/app.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"MedXpert\",\n",
    "    page_icon=\"üß†\",\n",
    "    layout=\"wide\",\n",
    ")\n",
    "\n",
    "st.title(\"üß† MedXpert: Medical Visual Question Answering & Diagnosis Assistant\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Welcome to **MedXpert**, a full-stack medical AI assistant that can:\n",
    "\n",
    "- üñºÔ∏è Analyze chest X-ray images\n",
    "- üîç Retrieve most similar cases and findings\n",
    "- üìù Generate diagnostic reports\n",
    "- üí¨ Answer clinical questions\n",
    "- üìä Compare cases and visualize results\n",
    "\n",
    "Navigate from the sidebar to start exploring different modules.\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab25793",
   "metadata": {},
   "outputs": [],
   "source": [
    "./data/processed/texts:\n",
    "total 6904\n",
    "-rw-rw-r-- 1 sysadm sysadm  698113 May 18 00:09 test.json\n",
    "-rw-rw-r-- 1 sysadm sysadm 5619568 May 18 00:09 train.json\n",
    "-rw-rw-r-- 1 sysadm sysadm  746886 May 18 00:09 validation.json\n",
    "\n",
    "./data/raw:\n",
    "total 0\n",
    "\n",
    "./models:\n",
    "total 12\n",
    "drwxrwxr-x 4 sysadm sysadm 4096 May 18 11:27 clip\n",
    "-rw-rw-r-- 1 sysadm sysadm    0 May  3 13:42 __init__.py\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May  3 00:16 llm\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May  3 13:47 __pycache__\n",
    "\n",
    "./models/clip:\n",
    "total 44\n",
    "-rw-rw-r-- 1 sysadm sysadm     0 May  3 00:16 config.yaml\n",
    "-rw-rw-r-- 1 sysadm sysadm 14372 May 18 11:39 dataset.py\n",
    "drwxrwxr-x 2 sysadm sysadm  4096 May 18 12:23 fine_tuned\n",
    "drwxrwxr-x 2 sysadm sysadm  4096 May 18 11:39 __pycache__\n",
    "-rw-rw-r-- 1 sysadm sysadm 17685 May 18 02:23 train.py\n",
    "-rw-rw-r-- 1 sysadm sysadm     0 May  3 00:16 utils.py\n",
    "\n",
    "./models/clip/fine_tuned:\n",
    "total 11235608\n",
    "-rw-rw-r-- 1 sysadm sysadm 1815823321 May 18 14:38 best_model.pt\n",
    "-rw-rw-r-- 1 sysadm sysadm 1815836105 May 18 14:29 checkpoint_epoch_1.pt\n",
    "-rw-rw-r-- 1 sysadm sysadm 1815836105 May 18 14:33 checkpoint_epoch_2.pt\n",
    "-rw-rw-r-- 1 sysadm sysadm 1815836105 May 18 14:37 checkpoint_epoch_3.pt\n",
    "-rw-rw-r-- 1 sysadm sysadm 1815836105 May 18 14:12 checkpoint_epoch_4.pt\n",
    "-rw-rw-r-- 1 sysadm sysadm 1815836105 May 18 14:16 checkpoint_epoch_5.pt\n",
    "-rw-rw-r-- 1 sysadm sysadm       1210 May 18 14:38 config.json\n",
    "-rw-rw-r-- 1 sysadm sysadm     524619 May 18 14:38 merges.txt\n",
    "-rw-rw-r-- 1 sysadm sysadm  605156676 May 18 14:38 model.safetensors\n",
    "-rw-rw-r-- 1 sysadm sysadm        504 May 18 14:38 preprocessor_config.json\n",
    "-rw-rw-r-- 1 sysadm sysadm        588 May 18 14:38 special_tokens_map.json\n",
    "-rw-rw-r-- 1 sysadm sysadm        774 May 18 14:38 tokenizer_config.json\n",
    "-rw-rw-r-- 1 sysadm sysadm    3642073 May 18 14:38 tokenizer.json\n",
    "-rw-rw-r-- 1 sysadm sysadm     862328 May 18 14:38 vocab.json\n",
    "\n",
    "./models/clip/__pycache__:\n",
    "total 8\n",
    "-rw-rw-r-- 1 sysadm sysadm 1059 May 18 11:39 dataset.cpython-310.pyc\n",
    "-rw-rw-r-- 1 sysadm sysadm 4032 May 18 02:24 train.cpython-310.pyc\n",
    "\n",
    "./results:\n",
    "total 16\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May 18 11:22 fine_tuned\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May 18 15:47 inference_plots\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May 18 12:32 plots\n",
    "-rw-rw-r-- 1 sysadm sysadm  775 May 18 14:37 train_history.tsv\n",
    "\n",
    "./results/fine_tuned:\n",
    "total 595916\n",
    "-rw-rw-r-- 1 sysadm sysadm      1210 May 18 02:57 config.json\n",
    "-rw-rw-r-- 1 sysadm sysadm    524619 May 18 02:57 merges.txt\n",
    "-rw-rw-r-- 1 sysadm sysadm 605156676 May 18 02:57 model.safetensors\n",
    "-rw-rw-r-- 1 sysadm sysadm       504 May 18 02:57 preprocessor_config.json\n",
    "-rw-rw-r-- 1 sysadm sysadm       588 May 18 02:57 special_tokens_map.json\n",
    "-rw-rw-r-- 1 sysadm sysadm       774 May 18 02:57 tokenizer_config.json\n",
    "-rw-rw-r-- 1 sysadm sysadm   3642073 May 18 02:57 tokenizer.json\n",
    "-rw-rw-r-- 1 sysadm sysadm    862328 May 18 02:57 vocab.json\n",
    "\n",
    "./results/inference_plots:\n",
    "total 296\n",
    "-rw-rw-r-- 1 sysadm sysadm 302287 May 18 15:47 query_0.png\n",
    "\n",
    "./results/plots:\n",
    "total 76\n",
    "-rw-rw-r-- 1 sysadm sysadm 74395 May 18 12:32 loss_plot.png\n",
    "\n",
    "./scripts:\n",
    "total 52\n",
    "drwxrwxr-x 3 sysadm sysadm 4096 May 18 12:48 data\n",
    "-rw-rw-r-- 1 sysadm sysadm    0 May  3 00:16 deploy_app.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 5357 May 18 16:30 eval_retrieval.py\n",
    "-rw-rw-r-- 1 sysadm sysadm    0 May  3 00:16 evaluate_model.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 3247 May 18 15:47 inference_plot.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 1814 May 18 16:22 inference_to_csv.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 1972 May 18 12:32 plot_losses.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 8728 May 14 16:53 preprocess_data.py\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May 18 14:25 __pycache__\n",
    "-rw-rw-r-- 1 sysadm sysadm 1144 May 18 16:48 run_inference_pipeline.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 2167 May 18 15:35 run_search_engine.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 2461 May 18 14:23 save_embedding.py\n",
    "\n",
    "\n",
    "./scripts/__pycache__:\n",
    "total 8\n",
    "-rw-rw-r-- 1 sysadm sysadm 3048 May 14 16:54 preprocess_data.cpython-310.pyc\n",
    "-rw-rw-r-- 1 sysadm sysadm 2805 May 18 14:25 save_embedding.cpython-310.pyc\n",
    "\n",
    "./src:\n",
    "total 24\n",
    "drwxrwxr-x 3 sysadm sysadm 4096 May  3 14:59 core\n",
    "-rw-rw-r-- 1 sysadm sysadm    0 May  3 14:57 __init__.py\n",
    "-rw-rw-r-- 1 sysadm sysadm  694 May 18 17:09 llm_providers.py\n",
    "drwxrwxr-x 3 sysadm sysadm 4096 May  3 16:52 pipeline\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May  3 14:59 __pycache__\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May  3 12:14 tests\n",
    "drwxrwxr-x 3 sysadm sysadm 4096 May  3 00:16 ui\n",
    "\n",
    "./src/core:\n",
    "total 8\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May 18 15:28 __pycache__\n",
    "-rw-rw-r-- 1 sysadm sysadm    0 May  3 00:16 report_generator.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 3189 May 18 15:27 search_engine.py\n",
    "-rw-rw-r-- 1 sysadm sysadm    0 May  3 00:16 utils.py\n",
    "\n",
    "./src/core/__pycache__:\n",
    "total 4\n",
    "-rw-rw-r-- 1 sysadm sysadm 2809 May 18 15:28 search_engine.cpython-310.pyc\n",
    "\n",
    "./src/pipeline:\n",
    "total 16\n",
    "-rw-rw-r-- 1 sysadm sysadm  803 May 18 16:49 blip_captioning.py\n",
    "-rw-rw-r-- 1 sysadm sysadm  342 May 18 16:50 clip_retrieval.py\n",
    "-rw-rw-r-- 1 sysadm sysadm  441 May 18 16:53 llm_report_generation.py\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May  3 16:52 __pycache__\n",
    "\n",
    "./src/pipeline/__pycache__:\n",
    "total 12\n",
    "-rw-rw-r-- 1 sysadm sysadm 804 May  3 16:52 blip_captioning.cpython-310.pyc\n",
    "-rw-rw-r-- 1 sysadm sysadm 518 May  3 16:52 clip_retrieval.cpython-310.pyc\n",
    "-rw-rw-r-- 1 sysadm sysadm 591 May  3 16:52 llm_report_generation.cpython-310.pyc\n",
    "\n",
    "./src/__pycache__:\n",
    "total 4\n",
    "-rw-rw-r-- 1 sysadm sysadm 136 May  3 14:59 __init__.cpython-310.pyc\n",
    "\n",
    "\n",
    "./src/ui:\n",
    "total 12\n",
    "-rw-rw-r-- 1 sysadm sysadm 5848 May 18 20:20 app.py\n",
    "drwxrwxr-x 2 sysadm sysadm 4096 May  3 00:16 pages\n",
    "\n",
    "./src/ui/pages:\n",
    "total 32\n",
    "-rw-rw-r-- 1 sysadm sysadm 5048 May 18 20:21 compare.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 3900 May 18 20:18 diagnosis.py\n",
    "-rw-rw-r-- 1 sysadm sysadm    0 May  3 00:16 home.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 5753 May 18 20:17 reports.py\n",
    "-rw-rw-r-- 1 sysadm sysadm 8475 May 18 20:19 search.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/sysadm/Music/MedXpert/src/pipeline/llm_report_generation.py\n",
    "def generate_report(blip_captions, retrieved_texts, llm_fn):\n",
    "    prompt = \"\"\"\n",
    "Below are findings extracted from multiple images and related radiology texts.\n",
    "\n",
    "Image Findings (via BLIP):\n",
    "\"\"\"\n",
    "    for c in blip_captions:\n",
    "        prompt += f\"- {c}\\n\"\n",
    "    \n",
    "    prompt += \"\\nReport Texts (via CLIP):\\n\"\n",
    "    for t in retrieved_texts:\n",
    "        prompt += f\"- {t}\\n\"\n",
    "\n",
    "    prompt += \"\\nGenerate a summarized radiology report:\"\n",
    "\n",
    "    return llm_fn(prompt)\n",
    "\n",
    "\n",
    "# /home/sysadm/Music/MedXpert/src/pipeline/blip_captioning.py\n",
    "\n",
    "def generate_blip_captions(image_paths):\n",
    "    from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "    from PIL import Image\n",
    "    import torch\n",
    "\n",
    "    # Load BLIP model and processor\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\")\n",
    "\n",
    "    captions = []\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        # Load and process each image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        inputs = processor(image, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        # Generate caption\n",
    "        output = model.generate(**inputs)\n",
    "        caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "        captions.append(caption)\n",
    "\n",
    "    return captions\n",
    "\n",
    "\n",
    "# /home/sysadm/Music/MedXpert/src/pipeline/clip_retrieval.py\n",
    "def retrieve_top_k(query, mode=\"text\", k=5):\n",
    "    from src.core.search_engine import search_image_by_text, search_text_by_image\n",
    "\n",
    "    if mode == \"text\":\n",
    "        return search_image_by_text(query, k=k)\n",
    "    elif mode == \"image\":\n",
    "        return search_text_by_image(query, k=k)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'text' or 'image'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
