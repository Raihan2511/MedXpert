{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6bdd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sysadm/Music/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load pretrained CLIP\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").cuda()\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f607f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MIMIC-CXR dataset\n",
    "train_dataset = load_dataset(\"itsanmolgupta/mimic-cxr-dataset\", split=\"train[:90%]\")  \n",
    "val_datset = load_dataset(\"itsanmolgupta/mimic-cxr-dataset\", split=\"train[:10%]\")\n",
    "train_dataset = train_dataset.filter(lambda x: x['impression'] is not None)\n",
    "val_dataset = val_datset.filter(lambda x: x['impression'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0490b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'findings', 'impression'],\n",
       "    num_rows: 27561\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fb30de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'findings', 'impression'],\n",
       "    num_rows: 3062\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb235ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       " 'findings': 'Lung volumes remain low. There are innumerable bilateral scattered small pulmonary nodules which are better demonstrated on recent CT. Mild pulmonary vascular congestion is stable. The cardiomediastinal silhouette and hilar contours are unchanged. Small pleural effusion in the right middle fissure is new. There is no new focal opacity to suggest pneumonia. There is no pneumothorax. ',\n",
       " 'impression': 'Low lung volumes and mild pulmonary vascular congestion is unchanged. New small right fissural pleural effusion. No new focal opacities to suggest pneumonia.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46b322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf52b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(examples):\n",
    "    images = [img.convert(\"RGB\") for img in examples[\"image\"]]\n",
    "    texts = [text if text else \"\" for text in examples[\"impression\"]]\n",
    "    inputs = processor(text=texts, images=images, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    return inputs\n",
    "\n",
    "# Custom PyTorch dataset wrapper\n",
    "class CLIPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.dataset[idx]\n",
    "        image = example[\"image\"].convert(\"RGB\")\n",
    "        text = example[\"impression\"]\n",
    "        return {\"image\": image, \"text\": text}\n",
    "\n",
    "# Collate function using CLIPProcessor\n",
    "def collate_fn(batch):\n",
    "    images = [b[\"image\"] for b in batch]\n",
    "    texts = [b[\"text\"] for b in batch]\n",
    "    return processor(text=texts, images=images, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4855519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f15dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_ds = CLIPDataset(train_dataset)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "# Validation DataLoader\n",
    "val_dataset = CLIPDataset(val_dataset)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d27c24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, ReduceLROnPlateau\n",
    "# from transformers import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e44d77",
   "metadata": {},
   "source": [
    "## CLAUDE SUGGESTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e82d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE SUGGESTION:\n",
    "\n",
    "\n",
    "\n",
    "def do_train(model, train_loader, optimizer, epoch, device, scheduler=None, max_grad_norm=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch, return_loss=True)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        if max_grad_norm > 0:\n",
    "            clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Report progress for long epochs\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"  Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Step the scheduler if provided\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return avg_train_loss, train_time\n",
    "\n",
    "@torch.no_grad()\n",
    "def do_eval(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch in val_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Get loss\n",
    "        outputs = model(**batch, return_loss=True)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Get image and text features\n",
    "        image_embeds = model.get_image_features(pixel_values=batch['pixel_values'])\n",
    "        text_embeds = model.get_text_features(\n",
    "            input_ids=batch['input_ids'], \n",
    "            attention_mask=batch['attention_mask']\n",
    "        )\n",
    "        \n",
    "        # Normalize\n",
    "        image_embeds = image_embeds / image_embeds.norm(dim=-1, keepdim=True)\n",
    "        text_embeds = text_embeds / text_embeds.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Compute similarity\n",
    "        logits = torch.matmul(image_embeds, text_embeds.T) * model.logit_scale.exp()\n",
    "        \n",
    "        # Prediction (diagonal elements should be highest)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        labels = torch.arange(len(preds)).to(device)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    val_time = time.time() - start_time\n",
    "    avg_val_loss = total_loss / len(val_loader)\n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_val_loss, val_acc, val_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4014d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fc86fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Epoch 1/10\n",
      "  Batch 0/1723 - Loss: 3.3927\n",
      "  Batch 50/1723 - Loss: 2.8823\n",
      "  Batch 100/1723 - Loss: 2.7791\n",
      "  Batch 150/1723 - Loss: 2.2495\n",
      "  Batch 200/1723 - Loss: 2.6175\n",
      "  Batch 250/1723 - Loss: 2.1857\n",
      "  Batch 300/1723 - Loss: 2.8325\n",
      "  Batch 350/1723 - Loss: 2.3628\n",
      "  Batch 400/1723 - Loss: 2.3473\n",
      "  Batch 450/1723 - Loss: 2.2286\n",
      "  Batch 500/1723 - Loss: 2.4369\n",
      "  Batch 550/1723 - Loss: 2.2994\n",
      "  Batch 600/1723 - Loss: 1.9284\n",
      "  Batch 650/1723 - Loss: 2.3107\n",
      "  Batch 700/1723 - Loss: 1.9258\n",
      "  Batch 750/1723 - Loss: 1.7282\n",
      "  Batch 800/1723 - Loss: 2.5525\n",
      "  Batch 850/1723 - Loss: 1.9190\n",
      "  Batch 900/1723 - Loss: 1.8173\n",
      "  Batch 950/1723 - Loss: 2.1459\n",
      "  Batch 1000/1723 - Loss: 2.1178\n",
      "  Batch 1050/1723 - Loss: 2.1140\n",
      "  Batch 1100/1723 - Loss: 2.3142\n",
      "  Batch 1150/1723 - Loss: 2.3100\n",
      "  Batch 1200/1723 - Loss: 1.8118\n",
      "  Batch 1250/1723 - Loss: 2.1673\n",
      "  Batch 1300/1723 - Loss: 2.0456\n",
      "  Batch 1350/1723 - Loss: 1.8644\n",
      "  Batch 1400/1723 - Loss: 2.1974\n",
      "  Batch 1450/1723 - Loss: 2.0318\n",
      "  Batch 1500/1723 - Loss: 2.0451\n",
      "  Batch 1550/1723 - Loss: 1.7949\n",
      "  Batch 1600/1723 - Loss: 2.1381\n",
      "  Batch 1650/1723 - Loss: 1.8823\n",
      "  Batch 1700/1723 - Loss: 1.9635\n",
      "\n",
      "🚀Epoch 1 Summary:\n",
      "✅ Epoch 1 - Train Loss: 2.2141 - Time: 420.61s\n",
      "📊 Validation Loss: 1.9079 | val_Acc: 33.6055% | Time: 42.18s\n",
      "\n",
      "🚀 Epoch 2/10\n",
      "  Batch 0/1723 - Loss: 1.4404\n",
      "  Batch 50/1723 - Loss: 1.5882\n",
      "  Batch 100/1723 - Loss: 1.6196\n",
      "  Batch 150/1723 - Loss: 1.5706\n",
      "  Batch 200/1723 - Loss: 1.7232\n",
      "  Batch 250/1723 - Loss: 1.8835\n",
      "  Batch 300/1723 - Loss: 1.3433\n",
      "  Batch 350/1723 - Loss: 1.6313\n",
      "  Batch 400/1723 - Loss: 1.5624\n",
      "  Batch 450/1723 - Loss: 1.9513\n",
      "  Batch 500/1723 - Loss: 1.1483\n",
      "  Batch 550/1723 - Loss: 2.0336\n",
      "  Batch 600/1723 - Loss: 1.6124\n",
      "  Batch 650/1723 - Loss: 1.4609\n",
      "  Batch 700/1723 - Loss: 1.4132\n",
      "  Batch 750/1723 - Loss: 1.9865\n",
      "  Batch 800/1723 - Loss: 1.4659\n",
      "  Batch 850/1723 - Loss: 1.5370\n",
      "  Batch 900/1723 - Loss: 1.9431\n",
      "  Batch 950/1723 - Loss: 1.6350\n",
      "  Batch 1000/1723 - Loss: 1.5233\n",
      "  Batch 1050/1723 - Loss: 1.5343\n",
      "  Batch 1100/1723 - Loss: 1.6770\n",
      "  Batch 1150/1723 - Loss: 1.8841\n",
      "  Batch 1200/1723 - Loss: 0.9193\n",
      "  Batch 1250/1723 - Loss: 1.2431\n",
      "  Batch 1300/1723 - Loss: 1.5226\n",
      "  Batch 1350/1723 - Loss: 1.6831\n",
      "  Batch 1400/1723 - Loss: 1.4587\n",
      "  Batch 1450/1723 - Loss: 1.6021\n",
      "  Batch 1500/1723 - Loss: 1.8295\n",
      "  Batch 1550/1723 - Loss: 1.2657\n",
      "  Batch 1600/1723 - Loss: 1.8664\n",
      "  Batch 1650/1723 - Loss: 1.5320\n",
      "  Batch 1700/1723 - Loss: 1.4671\n",
      "\n",
      "🚀Epoch 2 Summary:\n",
      "✅ Epoch 2 - Train Loss: 1.6730 - Time: 553.50s\n",
      "📊 Validation Loss: 1.4921 | val_Acc: 46.8975% | Time: 41.81s\n",
      "\n",
      "🚀 Epoch 3/10\n",
      "  Batch 0/1723 - Loss: 1.8648\n",
      "  Batch 50/1723 - Loss: 1.0983\n",
      "  Batch 100/1723 - Loss: 1.7990\n",
      "  Batch 150/1723 - Loss: 0.9800\n",
      "  Batch 200/1723 - Loss: 1.4540\n",
      "  Batch 250/1723 - Loss: 1.5714\n",
      "  Batch 300/1723 - Loss: 0.9833\n",
      "  Batch 350/1723 - Loss: 1.2125\n",
      "  Batch 400/1723 - Loss: 0.7781\n",
      "  Batch 450/1723 - Loss: 1.6571\n",
      "  Batch 500/1723 - Loss: 1.5823\n",
      "  Batch 550/1723 - Loss: 1.2217\n",
      "  Batch 600/1723 - Loss: 1.5535\n",
      "  Batch 650/1723 - Loss: 0.9976\n",
      "  Batch 700/1723 - Loss: 1.0024\n",
      "  Batch 750/1723 - Loss: 1.5614\n",
      "  Batch 800/1723 - Loss: 2.3826\n",
      "  Batch 850/1723 - Loss: 1.1764\n",
      "  Batch 900/1723 - Loss: 1.7971\n",
      "  Batch 950/1723 - Loss: 1.7184\n",
      "  Batch 1000/1723 - Loss: 1.2267\n",
      "  Batch 1050/1723 - Loss: 1.4504\n",
      "  Batch 1100/1723 - Loss: 1.4914\n",
      "  Batch 1150/1723 - Loss: 1.5565\n",
      "  Batch 1200/1723 - Loss: 0.9022\n",
      "  Batch 1250/1723 - Loss: 1.8177\n",
      "  Batch 1300/1723 - Loss: 1.4342\n",
      "  Batch 1350/1723 - Loss: 1.3283\n",
      "  Batch 1400/1723 - Loss: 1.8893\n",
      "  Batch 1450/1723 - Loss: 0.9751\n",
      "  Batch 1500/1723 - Loss: 1.2282\n",
      "  Batch 1550/1723 - Loss: 1.7934\n",
      "  Batch 1600/1723 - Loss: 1.4007\n",
      "  Batch 1650/1723 - Loss: 1.1066\n",
      "  Batch 1700/1723 - Loss: 1.2556\n",
      "\n",
      "🚀Epoch 3 Summary:\n",
      "✅ Epoch 3 - Train Loss: 1.2987 - Time: 560.52s\n",
      "📊 Validation Loss: 1.1569 | val_Acc: 57.5767% | Time: 42.26s\n",
      "\n",
      "🚀 Epoch 4/10\n",
      "  Batch 0/1723 - Loss: 1.1505\n",
      "  Batch 50/1723 - Loss: 1.3133\n",
      "  Batch 100/1723 - Loss: 0.9365\n",
      "  Batch 150/1723 - Loss: 0.9498\n",
      "  Batch 200/1723 - Loss: 1.0446\n",
      "  Batch 250/1723 - Loss: 0.8360\n",
      "  Batch 300/1723 - Loss: 1.3685\n",
      "  Batch 350/1723 - Loss: 0.7349\n",
      "  Batch 400/1723 - Loss: 0.4510\n",
      "  Batch 450/1723 - Loss: 0.8517\n",
      "  Batch 500/1723 - Loss: 0.8076\n",
      "  Batch 550/1723 - Loss: 0.8558\n",
      "  Batch 600/1723 - Loss: 0.5358\n",
      "  Batch 650/1723 - Loss: 1.1034\n",
      "  Batch 700/1723 - Loss: 0.7650\n",
      "  Batch 750/1723 - Loss: 0.8337\n",
      "  Batch 800/1723 - Loss: 0.6367\n",
      "  Batch 850/1723 - Loss: 1.2701\n",
      "  Batch 900/1723 - Loss: 1.5062\n",
      "  Batch 950/1723 - Loss: 0.9343\n",
      "  Batch 1000/1723 - Loss: 0.9870\n",
      "  Batch 1050/1723 - Loss: 0.9952\n",
      "  Batch 1100/1723 - Loss: 1.0244\n",
      "  Batch 1150/1723 - Loss: 0.6192\n",
      "  Batch 1200/1723 - Loss: 0.6438\n",
      "  Batch 1250/1723 - Loss: 0.9787\n",
      "  Batch 1300/1723 - Loss: 0.6035\n",
      "  Batch 1350/1723 - Loss: 0.4864\n",
      "  Batch 1400/1723 - Loss: 1.4273\n",
      "  Batch 1450/1723 - Loss: 0.8640\n",
      "  Batch 1500/1723 - Loss: 1.2125\n",
      "  Batch 1550/1723 - Loss: 0.5643\n",
      "  Batch 1600/1723 - Loss: 1.2446\n",
      "  Batch 1650/1723 - Loss: 0.8707\n",
      "  Batch 1700/1723 - Loss: 0.9549\n",
      "\n",
      "🚀Epoch 4 Summary:\n",
      "✅ Epoch 4 - Train Loss: 0.9590 - Time: 552.63s\n",
      "📊 Validation Loss: 0.8664 | val_Acc: 67.3416% | Time: 41.61s\n",
      "\n",
      "🚀 Epoch 5/10\n",
      "  Batch 0/1723 - Loss: 0.5377\n",
      "  Batch 50/1723 - Loss: 0.4796\n",
      "  Batch 100/1723 - Loss: 0.8867\n",
      "  Batch 150/1723 - Loss: 1.0335\n",
      "  Batch 200/1723 - Loss: 1.0526\n",
      "  Batch 250/1723 - Loss: 0.6222\n",
      "  Batch 300/1723 - Loss: 0.5351\n",
      "  Batch 350/1723 - Loss: 0.6316\n",
      "  Batch 400/1723 - Loss: 0.3548\n",
      "  Batch 450/1723 - Loss: 0.5639\n",
      "  Batch 500/1723 - Loss: 0.7140\n",
      "  Batch 550/1723 - Loss: 0.2834\n",
      "  Batch 600/1723 - Loss: 0.6454\n",
      "  Batch 650/1723 - Loss: 0.7844\n",
      "  Batch 700/1723 - Loss: 0.5463\n",
      "  Batch 750/1723 - Loss: 0.5543\n",
      "  Batch 800/1723 - Loss: 0.7460\n",
      "  Batch 850/1723 - Loss: 0.6488\n",
      "  Batch 900/1723 - Loss: 0.9041\n",
      "  Batch 950/1723 - Loss: 1.0086\n",
      "  Batch 1000/1723 - Loss: 0.8931\n",
      "  Batch 1050/1723 - Loss: 0.4816\n",
      "  Batch 1100/1723 - Loss: 0.8413\n",
      "  Batch 1150/1723 - Loss: 0.6984\n",
      "  Batch 1200/1723 - Loss: 0.6676\n",
      "  Batch 1250/1723 - Loss: 0.7789\n",
      "  Batch 1300/1723 - Loss: 0.4470\n",
      "  Batch 1350/1723 - Loss: 0.6865\n",
      "  Batch 1400/1723 - Loss: 0.6890\n",
      "  Batch 1450/1723 - Loss: 0.7598\n",
      "  Batch 1500/1723 - Loss: 0.9600\n",
      "  Batch 1550/1723 - Loss: 0.7733\n",
      "  Batch 1600/1723 - Loss: 0.3769\n",
      "  Batch 1650/1723 - Loss: 0.8726\n",
      "  Batch 1700/1723 - Loss: 1.2755\n",
      "\n",
      "🚀Epoch 5 Summary:\n",
      "✅ Epoch 5 - Train Loss: 0.6921 - Time: 576.38s\n",
      "📊 Validation Loss: 0.6282 | val_Acc: 73.8733% | Time: 42.39s\n",
      "\n",
      "🚀 Epoch 6/10\n",
      "  Batch 0/1723 - Loss: 0.4849\n",
      "  Batch 50/1723 - Loss: 0.4412\n",
      "  Batch 100/1723 - Loss: 0.2513\n",
      "  Batch 150/1723 - Loss: 0.4973\n",
      "  Batch 200/1723 - Loss: 0.3636\n",
      "  Batch 250/1723 - Loss: 0.6667\n",
      "  Batch 300/1723 - Loss: 0.4364\n",
      "  Batch 350/1723 - Loss: 0.3164\n",
      "  Batch 400/1723 - Loss: 0.3977\n",
      "  Batch 450/1723 - Loss: 0.5516\n",
      "  Batch 500/1723 - Loss: 0.4846\n",
      "  Batch 550/1723 - Loss: 0.4939\n",
      "  Batch 600/1723 - Loss: 0.2936\n",
      "  Batch 650/1723 - Loss: 0.7322\n",
      "  Batch 700/1723 - Loss: 0.6202\n",
      "  Batch 750/1723 - Loss: 0.2943\n",
      "  Batch 800/1723 - Loss: 0.5320\n",
      "  Batch 850/1723 - Loss: 0.5433\n",
      "  Batch 900/1723 - Loss: 0.5189\n",
      "  Batch 950/1723 - Loss: 0.5127\n",
      "  Batch 1000/1723 - Loss: 0.8149\n",
      "  Batch 1050/1723 - Loss: 0.6194\n",
      "  Batch 1100/1723 - Loss: 0.6512\n",
      "  Batch 1150/1723 - Loss: 0.5470\n",
      "  Batch 1200/1723 - Loss: 0.4815\n",
      "  Batch 1250/1723 - Loss: 0.6385\n",
      "  Batch 1300/1723 - Loss: 0.7582\n",
      "  Batch 1350/1723 - Loss: 0.6413\n",
      "  Batch 1400/1723 - Loss: 0.4338\n",
      "  Batch 1450/1723 - Loss: 0.4965\n",
      "  Batch 1500/1723 - Loss: 0.5949\n",
      "  Batch 1550/1723 - Loss: 0.5203\n",
      "  Batch 1600/1723 - Loss: 0.3963\n",
      "  Batch 1650/1723 - Loss: 0.7864\n",
      "  Batch 1700/1723 - Loss: 0.3204\n",
      "\n",
      "🚀Epoch 6 Summary:\n",
      "✅ Epoch 6 - Train Loss: 0.5218 - Time: 583.31s\n",
      "📊 Validation Loss: 0.5205 | val_Acc: 79.0660% | Time: 41.89s\n",
      "\n",
      "🚀 Epoch 7/10\n",
      "  Batch 0/1723 - Loss: 0.5477\n",
      "  Batch 50/1723 - Loss: 0.3966\n",
      "  Batch 100/1723 - Loss: 0.7603\n",
      "  Batch 150/1723 - Loss: 0.1603\n",
      "  Batch 200/1723 - Loss: 0.4218\n",
      "  Batch 250/1723 - Loss: 0.5121\n",
      "  Batch 300/1723 - Loss: 0.3319\n",
      "  Batch 350/1723 - Loss: 0.2603\n",
      "  Batch 400/1723 - Loss: 0.3875\n",
      "  Batch 450/1723 - Loss: 0.0544\n",
      "  Batch 500/1723 - Loss: 0.6847\n",
      "  Batch 550/1723 - Loss: 0.4437\n",
      "  Batch 600/1723 - Loss: 0.4045\n",
      "  Batch 650/1723 - Loss: 0.4224\n",
      "  Batch 700/1723 - Loss: 0.6766\n",
      "  Batch 750/1723 - Loss: 0.3133\n",
      "  Batch 800/1723 - Loss: 0.2088\n",
      "  Batch 850/1723 - Loss: 0.4588\n",
      "  Batch 900/1723 - Loss: 0.4206\n",
      "  Batch 950/1723 - Loss: 0.6135\n",
      "  Batch 1000/1723 - Loss: 0.3449\n",
      "  Batch 1050/1723 - Loss: 0.3685\n",
      "  Batch 1100/1723 - Loss: 0.3949\n",
      "  Batch 1150/1723 - Loss: 0.4067\n",
      "  Batch 1200/1723 - Loss: 0.5896\n",
      "  Batch 1250/1723 - Loss: 0.7928\n",
      "  Batch 1300/1723 - Loss: 0.5711\n",
      "  Batch 1350/1723 - Loss: 0.3815\n",
      "  Batch 1400/1723 - Loss: 0.3141\n",
      "  Batch 1450/1723 - Loss: 0.6088\n",
      "  Batch 1500/1723 - Loss: 0.1950\n",
      "  Batch 1550/1723 - Loss: 0.7778\n",
      "  Batch 1600/1723 - Loss: 0.6850\n",
      "  Batch 1650/1723 - Loss: 0.5830\n",
      "  Batch 1700/1723 - Loss: 0.2061\n",
      "\n",
      "🚀Epoch 7 Summary:\n",
      "✅ Epoch 7 - Train Loss: 0.4181 - Time: 390.60s\n",
      "📊 Validation Loss: 0.3953 | val_Acc: 83.8341% | Time: 25.23s\n",
      "\n",
      "🚀 Epoch 8/10\n",
      "  Batch 0/1723 - Loss: 0.3203\n",
      "  Batch 50/1723 - Loss: 0.3548\n",
      "  Batch 100/1723 - Loss: 0.4763\n",
      "  Batch 150/1723 - Loss: 0.7607\n",
      "  Batch 200/1723 - Loss: 0.0717\n",
      "  Batch 250/1723 - Loss: 0.2508\n",
      "  Batch 300/1723 - Loss: 0.2199\n",
      "  Batch 350/1723 - Loss: 0.4104\n",
      "  Batch 400/1723 - Loss: 0.4025\n",
      "  Batch 450/1723 - Loss: 0.5144\n",
      "  Batch 500/1723 - Loss: 0.3350\n",
      "  Batch 550/1723 - Loss: 0.0254\n",
      "  Batch 600/1723 - Loss: 0.1978\n",
      "  Batch 650/1723 - Loss: 0.3863\n",
      "  Batch 700/1723 - Loss: 0.6283\n",
      "  Batch 750/1723 - Loss: 0.4038\n",
      "  Batch 800/1723 - Loss: 0.2476\n",
      "  Batch 850/1723 - Loss: 0.1395\n",
      "  Batch 900/1723 - Loss: 0.2993\n",
      "  Batch 950/1723 - Loss: 0.3682\n",
      "  Batch 1000/1723 - Loss: 0.3860\n",
      "  Batch 1050/1723 - Loss: 0.2491\n",
      "  Batch 1100/1723 - Loss: 0.2186\n",
      "  Batch 1150/1723 - Loss: 0.3716\n",
      "  Batch 1200/1723 - Loss: 0.3380\n",
      "  Batch 1250/1723 - Loss: 0.5406\n",
      "  Batch 1300/1723 - Loss: 0.3069\n",
      "  Batch 1350/1723 - Loss: 0.2201\n",
      "  Batch 1400/1723 - Loss: 0.5696\n",
      "  Batch 1450/1723 - Loss: 0.6685\n",
      "  Batch 1500/1723 - Loss: 0.4525\n",
      "  Batch 1550/1723 - Loss: 0.1854\n",
      "  Batch 1600/1723 - Loss: 0.6871\n",
      "  Batch 1650/1723 - Loss: 0.2606\n",
      "  Batch 1700/1723 - Loss: 0.2323\n",
      "\n",
      "🚀Epoch 8 Summary:\n",
      "✅ Epoch 8 - Train Loss: 0.3457 - Time: 327.73s\n",
      "📊 Validation Loss: 0.3759 | val_Acc: 84.3893% | Time: 25.69s\n",
      "\n",
      "🚀 Epoch 9/10\n",
      "  Batch 0/1723 - Loss: 0.0688\n",
      "  Batch 50/1723 - Loss: 0.0923\n",
      "  Batch 100/1723 - Loss: 0.0455\n",
      "  Batch 150/1723 - Loss: 0.2339\n",
      "  Batch 200/1723 - Loss: 0.1749\n",
      "  Batch 250/1723 - Loss: 0.3422\n",
      "  Batch 300/1723 - Loss: 0.2715\n",
      "  Batch 350/1723 - Loss: 0.0549\n",
      "  Batch 400/1723 - Loss: 0.1023\n",
      "  Batch 450/1723 - Loss: 0.3816\n",
      "  Batch 500/1723 - Loss: 0.3126\n",
      "  Batch 550/1723 - Loss: 0.2408\n",
      "  Batch 600/1723 - Loss: 0.1138\n",
      "  Batch 650/1723 - Loss: 0.6077\n",
      "  Batch 700/1723 - Loss: 0.1825\n",
      "  Batch 750/1723 - Loss: 0.2879\n",
      "  Batch 800/1723 - Loss: 0.2815\n",
      "  Batch 850/1723 - Loss: 0.2331\n",
      "  Batch 900/1723 - Loss: 0.3439\n",
      "  Batch 950/1723 - Loss: 0.1732\n",
      "  Batch 1000/1723 - Loss: 0.3053\n",
      "  Batch 1050/1723 - Loss: 0.1349\n",
      "  Batch 1100/1723 - Loss: 0.1984\n",
      "  Batch 1150/1723 - Loss: 0.5452\n",
      "  Batch 1200/1723 - Loss: 0.4856\n",
      "  Batch 1250/1723 - Loss: 0.1043\n",
      "  Batch 1300/1723 - Loss: 0.2745\n",
      "  Batch 1350/1723 - Loss: 0.3532\n",
      "  Batch 1400/1723 - Loss: 0.5309\n",
      "  Batch 1450/1723 - Loss: 0.3408\n",
      "  Batch 1500/1723 - Loss: 0.8408\n",
      "  Batch 1550/1723 - Loss: 0.1648\n",
      "  Batch 1600/1723 - Loss: 0.2456\n",
      "  Batch 1650/1723 - Loss: 0.1796\n",
      "  Batch 1700/1723 - Loss: 0.6033\n",
      "\n",
      "🚀Epoch 9 Summary:\n",
      "✅ Epoch 9 - Train Loss: 0.3047 - Time: 325.11s\n",
      "📊 Validation Loss: 0.3824 | val_Acc: 84.4873% | Time: 25.75s\n",
      "\n",
      "🚀 Epoch 10/10\n",
      "  Batch 0/1723 - Loss: 0.0206\n",
      "  Batch 50/1723 - Loss: 0.1155\n",
      "  Batch 100/1723 - Loss: 0.2228\n",
      "  Batch 150/1723 - Loss: 0.7448\n",
      "  Batch 200/1723 - Loss: 0.1420\n",
      "  Batch 250/1723 - Loss: 0.0669\n",
      "  Batch 300/1723 - Loss: 0.2355\n",
      "  Batch 350/1723 - Loss: 0.4590\n",
      "  Batch 400/1723 - Loss: 0.1347\n",
      "  Batch 450/1723 - Loss: 0.5021\n",
      "  Batch 500/1723 - Loss: 0.1817\n",
      "  Batch 550/1723 - Loss: 0.2757\n",
      "  Batch 600/1723 - Loss: 0.0241\n",
      "  Batch 650/1723 - Loss: 0.1621\n",
      "  Batch 700/1723 - Loss: 0.3647\n",
      "  Batch 750/1723 - Loss: 0.2497\n",
      "  Batch 800/1723 - Loss: 0.6548\n",
      "  Batch 850/1723 - Loss: 0.4224\n",
      "  Batch 900/1723 - Loss: 0.2917\n",
      "  Batch 950/1723 - Loss: 0.0986\n",
      "  Batch 1000/1723 - Loss: 0.3408\n",
      "  Batch 1050/1723 - Loss: 0.0335\n",
      "  Batch 1100/1723 - Loss: 0.6428\n",
      "  Batch 1150/1723 - Loss: 0.3579\n",
      "  Batch 1200/1723 - Loss: 0.1215\n",
      "  Batch 1250/1723 - Loss: 0.3527\n",
      "  Batch 1300/1723 - Loss: 0.1716\n",
      "  Batch 1350/1723 - Loss: 0.2807\n",
      "  Batch 1400/1723 - Loss: 0.2996\n",
      "  Batch 1450/1723 - Loss: 0.4819\n",
      "  Batch 1500/1723 - Loss: 0.3483\n",
      "  Batch 1550/1723 - Loss: 0.2021\n",
      "  Batch 1600/1723 - Loss: 0.2144\n",
      "  Batch 1650/1723 - Loss: 0.3727\n",
      "  Batch 1700/1723 - Loss: 0.1005\n",
      "\n",
      "🚀Epoch 10 Summary:\n",
      "✅ Epoch 10 - Train Loss: 0.2655 - Time: 325.97s\n",
      "📊 Validation Loss: 0.2915 | val_Acc: 88.1777% | Time: 25.35s\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "EPOCHS=10\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n🚀 Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    avg_train_loss, train_time = do_train(model, train_loader, optimizer, epoch, device=\"cuda\")\n",
    "    avg_val_loss,val_acc, val_time = do_eval(model, val_loader, device=\"cuda\")\n",
    "    print(f\"\\n🚀Epoch {epoch+1} Summary:\")\n",
    "    print(f\"✅ Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f} - Time: {train_time:.2f}s\")\n",
    "    print(f\"📊 Validation Loss: {avg_val_loss:.4f} | val_Acc: {val_acc*100:.4f}% | Time: {val_time:.2f}s\")\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2636e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda932ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_losses\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIP Fine-Tuning Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.title(\"CLIP Fine-Tuning Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
    "plt.title(\"CLIP Val Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
