{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plthj\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import torch\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "\n",
    "# def plot_training_metrics(\n",
    "#     train_losses, \n",
    "#     val_losses, \n",
    "#     val_accuracies=None, \n",
    "#     learning_rates=None, \n",
    "#     save_dir='plots'\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Plot training metrics including losses, accuracy, and learning rate.\n",
    "    \n",
    "#     Args:\n",
    "#         train_losses: List of training losses per epoch\n",
    "#         val_losses: List of validation losses per epoch\n",
    "#         val_accuracies: List of validation accuracies per epoch (optional)\n",
    "#         learning_rates: List of learning rates per epoch (optional)\n",
    "#         save_dir: Directory to save the plots\n",
    "#     \"\"\"\n",
    "#     # Create directory if it doesn't exist\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "#     # Generate timestamp for unique filenames\n",
    "#     timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "#     # Set style for plots\n",
    "#     plt.style.use('ggplot')\n",
    "    \n",
    "#     # Plot losses\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "#     plt.plot(epochs, train_losses, 'b-o', label='Training Loss')\n",
    "#     plt.plot(epochs, val_losses, 'r-o', label='Validation Loss')\n",
    "    \n",
    "#     plt.title('CLIP Training and Validation Loss')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     # Save the loss plot\n",
    "#     loss_plot_path = os.path.join(save_dir, f'clip_losses_{timestamp}.png')\n",
    "#     plt.savefig(loss_plot_path, dpi=300, bbox_inches='tight')\n",
    "#     print(f\"Loss plot saved to {loss_plot_path}\")\n",
    "#     plt.close()\n",
    "    \n",
    "#     # Plot validation accuracy if provided\n",
    "#     if val_accuracies:\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(epochs, val_accuracies, 'g-o')\n",
    "#         plt.title('CLIP Validation Accuracy')\n",
    "#         plt.xlabel('Epochs')\n",
    "#         plt.ylabel('Accuracy (%)')\n",
    "#         plt.grid(True)\n",
    "        \n",
    "#         # Save the accuracy plot\n",
    "#         acc_plot_path = os.path.join(save_dir, f'clip_accuracy_{timestamp}.png')\n",
    "#         plt.savefig(acc_plot_path, dpi=300, bbox_inches='tight')\n",
    "#         print(f\"Accuracy plot saved to {acc_plot_path}\")\n",
    "#         plt.close()\n",
    "    \n",
    "#     # Plot learning rate if provided\n",
    "#     if learning_rates:\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(epochs, learning_rates, 'purple', marker='o')\n",
    "#         plt.title('Learning Rate Schedule')\n",
    "#         plt.xlabel('Epochs')\n",
    "#         plt.ylabel('Learning Rate')\n",
    "#         plt.yscale('log')  # Log scale often better for LR visualization\n",
    "#         plt.grid(True)\n",
    "        \n",
    "#         # Save the learning rate plot\n",
    "#         lr_plot_path = os.path.join(save_dir, f'clip_lr_schedule_{timestamp}.png')\n",
    "#         plt.savefig(lr_plot_path, dpi=300, bbox_inches='tight')\n",
    "#         print(f\"Learning rate plot saved to {lr_plot_path}\")\n",
    "#         plt.close()\n",
    "    \n",
    "#     # Combined plot with dual y-axis\n",
    "#     if val_accuracies:\n",
    "#         fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "#         # Loss curves on left y-axis\n",
    "#         ax1.set_xlabel('Epochs')\n",
    "#         ax1.set_ylabel('Loss', color='tab:blue')\n",
    "#         ax1.plot(epochs, train_losses, 'b-o', label='Training Loss')\n",
    "#         ax1.plot(epochs, val_losses, 'r-o', label='Validation Loss')\n",
    "#         ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "        \n",
    "#         # Accuracy curve on right y-axis\n",
    "#         ax2 = ax1.twinx()\n",
    "#         ax2.set_ylabel('Accuracy (%)', color='tab:green')\n",
    "#         ax2.plot(epochs, val_accuracies, 'g-o', label='Validation Accuracy')\n",
    "#         ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "        \n",
    "#         # Add legend\n",
    "#         lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "#         lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "#         ax1.legend(lines1 + lines2, labels1 + labels2, loc='center right')\n",
    "        \n",
    "#         plt.title('CLIP Training Metrics')\n",
    "#         plt.grid(True, alpha=0.3)\n",
    "        \n",
    "#         # Save the combined plot\n",
    "#         combined_plot_path = os.path.join(save_dir, f'clip_combined_metrics_{timestamp}.png')\n",
    "#         plt.savefig(combined_plot_path, dpi=300, bbox_inches='tight')\n",
    "#         print(f\"Combined metrics plot saved to {combined_plot_path}\")\n",
    "#         plt.close()\n",
    "\n",
    "\n",
    "# # Updated training function to track and plot metrics\n",
    "# def train_clip_model_with_plots(\n",
    "#     model,\n",
    "#     train_loader,\n",
    "#     val_loader,\n",
    "#     num_epochs=10,\n",
    "#     learning_rate=2e-5,\n",
    "#     weight_decay=0.01,\n",
    "#     scheduler_type=\"cosine\",\n",
    "#     warmup_epochs=1,\n",
    "#     checkpoint_dir=\"checkpoints\",\n",
    "#     plots_dir=\"plots\",\n",
    "#     device=None\n",
    "# ):\n",
    "#     if device is None:\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "#     # Move model to device\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     # Create optimizer\n",
    "#     optimizer = torch.optim.AdamW(\n",
    "#         model.parameters(),\n",
    "#         lr=learning_rate,\n",
    "#         weight_decay=weight_decay\n",
    "#     )\n",
    "    \n",
    "#     # Create scheduler based on type\n",
    "#     scheduler = None\n",
    "#     if scheduler_type == \"cosine\":\n",
    "#         # Cosine decay from initial lr to near-zero\n",
    "#         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#             optimizer, \n",
    "#             T_max=num_epochs - warmup_epochs,\n",
    "#             eta_min=1e-6\n",
    "#         )\n",
    "        \n",
    "#         # Optional: Warmup scheduler for first few epochs\n",
    "#         if warmup_epochs > 0:\n",
    "#             warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "#                 optimizer, \n",
    "#                 start_factor=0.1, \n",
    "#                 end_factor=1.0, \n",
    "#                 total_iters=warmup_epochs\n",
    "#             )\n",
    "            \n",
    "#     elif scheduler_type == \"linear\":\n",
    "#         # Linear decay\n",
    "#         scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "#             optimizer,\n",
    "#             start_factor=1.0,\n",
    "#             end_factor=0.1,\n",
    "#             total_iters=num_epochs\n",
    "#         )\n",
    "        \n",
    "#     elif scheduler_type == \"plateau\":\n",
    "#         # Reduce LR when validation loss plateaus\n",
    "#         scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#             optimizer,\n",
    "#             mode='min',\n",
    "#             factor=0.5,\n",
    "#             patience=2,\n",
    "#             verbose=True\n",
    "#         )\n",
    "    \n",
    "#     # Create directories if they don't exist\n",
    "#     os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "#     os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "#     # Metrics tracking\n",
    "#     train_losses = []\n",
    "#     val_losses = []\n",
    "#     val_accuracies = []\n",
    "#     learning_rates = []\n",
    "    \n",
    "#     best_val_acc = 0\n",
    "#     best_model_path = None\n",
    "    \n",
    "#     # Training loop\n",
    "#     for epoch in range(num_epochs):\n",
    "#         current_lr = optimizer.param_groups[0]['lr']\n",
    "#         learning_rates.append(current_lr)\n",
    "        \n",
    "#         print(f\"\\n== Epoch {epoch+1}/{num_epochs} ==\")\n",
    "#         print(f\"Learning rate: {current_lr:.2e}\")\n",
    "        \n",
    "#         # Training phase\n",
    "#         train_loss, train_time = do_train(\n",
    "#             model,\n",
    "#             train_loader,\n",
    "#             optimizer,\n",
    "#             epoch,\n",
    "#             device,\n",
    "#             scheduler=(warmup_scheduler if epoch < warmup_epochs and warmup_epochs > 0 else None),\n",
    "#             max_grad_norm=1.0\n",
    "#         )\n",
    "        \n",
    "#         # Evaluation phase\n",
    "#         val_loss, val_acc, val_time = do_eval(model, val_loader, device)\n",
    "        \n",
    "#         # Record metrics\n",
    "#         train_losses.append(train_loss)\n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accuracies.append(val_acc * 100)  # Convert to percentage\n",
    "        \n",
    "#         # Step the scheduler\n",
    "#         if scheduler_type == \"plateau\":\n",
    "#             scheduler.step(val_loss)\n",
    "#         elif scheduler is not None and epoch >= warmup_epochs:\n",
    "#             scheduler.step()\n",
    "#         elif warmup_epochs > 0 and epoch < warmup_epochs:\n",
    "#             warmup_scheduler.step()\n",
    "        \n",
    "#         # Save checkpoint if it's the best model so far\n",
    "#         if val_acc > best_val_acc:\n",
    "#             best_val_acc = val_acc\n",
    "#             checkpoint_path = os.path.join(checkpoint_dir, f\"clip_best_model_epoch{epoch+1}.pt\")\n",
    "            \n",
    "#             # Save model state\n",
    "#             torch.save({\n",
    "#                 'epoch': epoch + 1,\n",
    "#                 'model_state_dict': model.state_dict(),\n",
    "#                 'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                 'val_acc': val_acc,\n",
    "#                 'val_loss': val_loss,\n",
    "#                 'train_losses': train_losses,\n",
    "#                 'val_losses': val_losses,\n",
    "#                 'val_accuracies': val_accuracies,\n",
    "#                 'learning_rates': learning_rates\n",
    "#             }, checkpoint_path)\n",
    "            \n",
    "#             best_model_path = checkpoint_path\n",
    "#             print(f\"ðŸ”¥ New best model saved to {checkpoint_path}\")\n",
    "        \n",
    "#         # Plot metrics every few epochs or at the end\n",
    "#         if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n",
    "#             plot_training_metrics(\n",
    "#                 train_losses, \n",
    "#                 val_losses, \n",
    "#                 val_accuracies, \n",
    "#                 learning_rates,\n",
    "#                 save_dir=plots_dir\n",
    "#             )\n",
    "    \n",
    "#     # Final plots\n",
    "#     plot_training_metrics(\n",
    "#         train_losses, \n",
    "#         val_losses, \n",
    "#         val_accuracies, \n",
    "#         learning_rates,\n",
    "#         save_dir=plots_dir\n",
    "#     )\n",
    "    \n",
    "#     # Save training history to CSV\n",
    "#     history_df = pd.DataFrame({\n",
    "#         'epoch': list(range(1, num_epochs + 1)),\n",
    "#         'train_loss': train_losses,\n",
    "#         'val_loss': val_losses,\n",
    "#         'val_accuracy': val_accuracies,\n",
    "#         'learning_rate': learning_rates\n",
    "#     })\n",
    "    \n",
    "#     history_path = os.path.join(plots_dir, f'training_history_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv')\n",
    "#     history_df.to_csv(history_path, index=False)\n",
    "#     print(f\"Training history saved to {history_path}\")\n",
    "    \n",
    "#     print(f\"\\n== Training Complete ==\")\n",
    "#     print(f\"Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "#     print(f\"Best model saved at: {best_model_path}\")\n",
    "    \n",
    "#     return model, best_model_path, history_df\n",
    "\n",
    "\n",
    "# # Example usage with the do_train and do_eval functions from previous code\n",
    "# def do_train(model, train_loader, optimizer, epoch, device, scheduler=None, max_grad_norm=1.0):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     for batch_idx, batch in enumerate(train_loader):\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "#         # Forward pass\n",
    "#         outputs = model(**batch, return_loss=True)\n",
    "#         loss = outputs.loss\n",
    "        \n",
    "#         # Backward pass\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Gradient clipping for stability\n",
    "#         if max_grad_norm > 0:\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         # Report progress for long epochs\n",
    "#         if batch_idx % 50 == 0:\n",
    "#             print(f\"  Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "    \n",
    "#     train_time = time.time() - start_time\n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "#     print(f\"âœ… Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f} - Time: {train_time:.2f}s\")\n",
    "#     return avg_train_loss, train_time\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def do_eval(model, val_loader, device):\n",
    "#     model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     for batch in val_loader:\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "#         # Get loss\n",
    "#         outputs = model(**batch, return_loss=True)\n",
    "#         loss = outputs.loss\n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         # Get image and text features\n",
    "#         image_embeds = model.get_image_features(pixel_values=batch['pixel_values'])\n",
    "#         text_embeds = model.get_text_features(\n",
    "#             input_ids=batch['input_ids'], \n",
    "#             attention_mask=batch['attention_mask']\n",
    "#         )\n",
    "        \n",
    "#         # Normalize\n",
    "#         image_embeds = image_embeds / image_embeds.norm(dim=-1, keepdim=True)\n",
    "#         text_embeds = text_embeds / text_embeds.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "#         # Compute similarity\n",
    "#         logits = torch.matmul(image_embeds, text_embeds.T) * model.logit_scale.exp()\n",
    "        \n",
    "#         # Prediction (diagonal elements should be highest)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "#         labels = torch.arange(len(preds)).to(device)\n",
    "        \n",
    "#         all_preds.extend(preds.cpu().tolist())\n",
    "#         all_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "#     val_time = time.time() - start_time\n",
    "#     avg_val_loss = total_loss / len(val_loader)\n",
    "#     val_acc = len([i for i, (p, l) in enumerate(zip(all_preds, all_labels)) if p == l]) / len(all_preds)\n",
    "    \n",
    "#     print(f\"ðŸ“Š Validation Loss: {avg_val_loss:.4f} - Val_Accuracy: {val_acc*100:.2f}% - Time: {val_time:.2f}s\")\n",
    "#     return avg_val_loss, val_acc, val_time\n",
    "\n",
    "\n",
    "# # Example of how to use the plotting functionality\n",
    "# if __name__ == \"__main__\":\n",
    "#     from transformers import CLIPModel, CLIPProcessor\n",
    "    \n",
    "#     # Load pre-trained CLIP model and processor\n",
    "#     model_name = \"openai/clip-vit-base-patch32\"\n",
    "#     model = CLIPModel.from_pretrained(model_name)\n",
    "#     processor = CLIPProcessor.from_pretrained(model_name)\n",
    "    \n",
    "#     # Prepare your datasets and dataloaders here\n",
    "#     # train_dataset = ...\n",
    "#     # val_dataset = ...\n",
    "#     # train_loader = ...\n",
    "#     # val_loader = ...\n",
    "    \n",
    "#     # Train the model with plotting\n",
    "#     trained_model, best_model_path, history_df = train_clip_model_with_plots(\n",
    "#         model=model,\n",
    "#         train_loader=train_loader,\n",
    "#         val_loader=val_loader,\n",
    "#         num_epochs=20,\n",
    "#         learning_rate=2e-5,\n",
    "#         scheduler_type=\"cosine\",\n",
    "#         warmup_epochs=2,\n",
    "#         plots_dir=\"clip_training_plots\"\n",
    "#     )\n",
    "    \n",
    "#     # If you want to plot metrics from a saved checkpoint:\n",
    "#     \"\"\"\n",
    "#     checkpoint = torch.load('path/to/checkpoint.pt')\n",
    "#     plot_training_metrics(\n",
    "#         checkpoint['train_losses'],\n",
    "#         checkpoint['val_losses'],\n",
    "#         checkpoint['val_accuracies'],\n",
    "#         checkpoint['learning_rates'],\n",
    "#         save_dir='restored_plots'\n",
    "#     )\n",
    "#     \"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
